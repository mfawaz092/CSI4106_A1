{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**CSI 4106 Introduction to Artificial Intelligence** <br/>\n",
        "*Assignment 1: Data Preparation*\n",
        "\n",
        "# Identification\n",
        "\n",
        "Name: Mahmoud Fawaz <br/>\n",
        "Student Number: 300162088\n",
        "\n",
        "# Exploratory Analysis\n",
        "\n",
        "## Import important libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Read Dataset\n",
        "\n",
        "As outlined in the project description, it should be possible for the correctors to ecute your notebook without requiring any downloads.\n",
        "\n",
        "To facilitate access to the dataset without the need for downloads, use the data ovided in the public GitHub repository and provide a link to the raw version of the taset.\n",
        "\n",
        "The link to the raw version is as follows:\n",
        "\n",
        "*https://raw.githubusercontent.com/GITHUB_USERNAME/REPOSITORY_NAME/main/DATASETNAME.v*\n",
        "\n",
        "For example:\n",
        "\n",
        "[https://github.com/turcotte/csi4106-f24/blob/main/assignments-data/a1/01/glass.csv]ttps://github.com/turcotte/csi4106-f24/blob/main/assignments-data/a1/01/glass.csv)\n",
        "\n",
        "Now provide the link to YOUR dataset and read the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\mfawa\\AppData\\Local\\Temp\\ipykernel_29144\\204905847.py:20: DtypeWarning: Columns (26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  train_dataset = pd.read_csv(train_url)\n"
          ]
        }
      ],
      "source": [
        "glass_url = \"https://raw.githubusercontent.com/mfawaz092/CSI4106_A1/main/datasets/01/glass.csv\"\n",
        "glass_dataset = pd.read_csv(glass_url)\n",
        "\n",
        "dermatology_url = \"https://raw.githubusercontent.com/mfawaz092/CSI4106_A1/main/datasets/02/dermatology_database_1.csv\"\n",
        "dermatology_dataset = pd.read_csv(dermatology_url)\n",
        "\n",
        "MHR_url = \"https://raw.githubusercontent.com/mfawaz092/CSI4106_A1/main/datasets/03/Maternal%20Health%20Risk%20Data%20Set.csv\"\n",
        "MHR_dataset = pd.read_csv(MHR_url)\n",
        "\n",
        "car_url = \"https://raw.githubusercontent.com/mfawaz092/CSI4106_A1/main/datasets/04/car.data\"\n",
        "car_dataset = pd.read_csv(car_url)\n",
        "\n",
        "wine_url = \"https://raw.githubusercontent.com/mfawaz092/CSI4106_A1/main/datasets/05/WineQT.csv\"\n",
        "wine_dataset = pd.read_csv(wine_url)\n",
        "\n",
        "P16_url = \"https://raw.githubusercontent.com/mfawaz092/CSI4106_A1/main/datasets/06/16P.csv\"\n",
        "P16_dataset = pd.read_csv(P16_url, encoding='ISO-8859-1')\n",
        "\n",
        "train_url = \"https://raw.githubusercontent.com/mfawaz092/CSI4106_A1/main/datasets/07/train.csv\"\n",
        "train_dataset = pd.read_csv(train_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Guidelines\n",
        "\n",
        "The following are the questions for Assignment 1. Under each question, we have provided an initial code cell. You are encouraged to add additional code cells to maintain logical separation of your code. For instance, place the definition of a function in one cell and its execution in a subsequent cell. This approach will help preserve clarity and enhance readability by avoiding the inclusion of excessive code within a single cell.\n",
        "\n",
        "1. **Analysis of Missing Values**: Examine the datasets to identify and assess ssing values in various attributes. Missing values may be represented by symbols ch as '?', empty strings, or other placeholders.\n",
        "\n",
        "    1.1 In the list of options, what are the datasets that contain missing values? ecifically, which attribute or attributes has missing values?\n",
        "\n",
        "    1.2 Describe the methodology used for this investigation, and provide the rresponding code.\n",
        "\n",
        "    1.1 Data imputation involves replacing missing or incomplete data with substituted values to preserve the dataset's integrity for subsequent analysis. Propose imputation strategies for each attribute with missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Glass Identification Dataset has: 0 missing values\n",
            "Dermatology Dataset has: 8 missing values\n",
            "Maternal Health Risk Dataset has: 0 missing values\n",
            "Car Dataset has: 0 missing values\n",
            "Wine Quality Dataset has: 0 missing values\n",
            "16 Personalities Dataset has: 0 missing values\n",
            "Credit Score Dataset has: 94991 missing values\n",
            "\n",
            "Attributes with missing values in the Dermatology Dataset are:\n",
            "age    8\n",
            "dtype: int64\n",
            "\n",
            "Attributes with missing values in the Credit Score Dataset are:\n",
            "Name                        9985\n",
            "SSN                         5572\n",
            "Occupation                  7062\n",
            "Monthly_Inhand_Salary      15002\n",
            "Type_of_Loan               11408\n",
            "Num_of_Delayed_Payment      7002\n",
            "Changed_Credit_Limit        2091\n",
            "Num_Credit_Inquiries        1965\n",
            "Credit_Mix                 20195\n",
            "Credit_History_Age          9030\n",
            "Amount_invested_monthly     4479\n",
            "Monthly_Balance             1200\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Checking if the Glass Identification Dataset has any missing values (based on the kaggle description, we are looking for null values)\n",
        "glass_MVs = glass_dataset.isnull().sum().sum()\n",
        "print(\"Glass Identification Dataset has:\", glass_MVs , \"missing values\")\n",
        "\n",
        "# Checking if the Dermatology Dataset has any missing values (based on the kaggle description, we are looking for \"?\" values)\n",
        "dermatology_MVs = (dermatology_dataset == '?').sum().sum()\n",
        "print(\"Dermatology Dataset has:\", dermatology_MVs, \"missing values\")\n",
        "\n",
        "# Checking if the Maternal Health Risk Dataset has any missing values (based on the description, we are looking for null values)\n",
        "MHR_MVs = MHR_dataset.isnull().sum().sum()\n",
        "print(\"Maternal Health Risk Dataset has:\", MHR_MVs , \"missing values\")\n",
        "\n",
        "# Checking if the Car Dataset has any missing values (based on the description, we are looking for null values)\n",
        "car_MVs = car_dataset.isnull().sum().sum()\n",
        "print(\"Car Dataset has:\", car_MVs , \"missing values\")\n",
        "\n",
        "# Checking if the Wine Quality Dataset has any missing values (based on the description, we are looking for null values)\n",
        "wine_MVs = wine_dataset.isnull().sum().sum()\n",
        "print(\"Wine Quality Dataset has:\", wine_MVs , \"missing values\")\n",
        "\n",
        "# Checking if the 16 Personalities Dataset has any missing values (based on the description, we are looking for null values)\n",
        "P16_MVs = P16_dataset.isnull().sum().sum()\n",
        "print(\"16 Personalities Dataset has:\", P16_MVs , \"missing values\")\n",
        "\n",
        "# Checking if the Credit Score Dataset has any missing values (based on the description, we are looking for null values, \"_______\", \n",
        "# and \"#F%$D@*&8\")\n",
        "CS_null_MVs = train_dataset.isnull().sum().sum()\n",
        "CS_underscore_MVs = (train_dataset == \"_______\").sum().sum()\n",
        "CS_underscore2_MVs = (train_dataset == \"_\").sum().sum()\n",
        "CS_placeholder_MVs = (train_dataset == \"#F%$D@*&8\").sum().sum()\n",
        "print(\"Credit Score Dataset has:\", (CS_null_MVs + CS_underscore_MVs + CS_underscore2_MVs + CS_placeholder_MVs) , \"missing values\")\n",
        "\n",
        "print()\n",
        "\n",
        "######################################################################################################################################\n",
        "\n",
        "# The only datasets with missing values are Dermatology and Credit Score.\n",
        "\n",
        "# Checking which attributes in the Dermatology dataset have missing values\n",
        "dermatology_abs = (dermatology_dataset == '?').sum()\n",
        "print(\"Attributes with missing values in the Dermatology Dataset are:\")\n",
        "print(dermatology_abs[dermatology_abs != 0])\n",
        "\n",
        "print()\n",
        "\n",
        "# Checking which attributes in the Credit Score dataset have missing values\n",
        "CS_abs = train_dataset.isnull().sum()\n",
        "CS_abs = CS_abs.add((train_dataset == '_').sum())\n",
        "CS_abs = CS_abs.add((train_dataset == \"_______\").sum())\n",
        "CS_abs = CS_abs.add((train_dataset == \"#F%$D@*&8\").sum())\n",
        "print(\"Attributes with missing values in the Credit Score Dataset are:\")\n",
        "print(CS_abs[CS_abs != 0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. **Select and familiarize yourself with a classification task:** Choose one of e provided datasets for further investigation. It is advisable to select a dataset ntaining a sufficiently large number of examples, ideally around 1,000, to ensure bust results when applying machine learning algorithms in the subsequent assignment.\n",
        "\n",
        "    2.1 What is the objective of the task? Is it intended for a specific plication? Do you possess expertise in this particular domain of application?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Maternal Health Risk Dataset\n",
        "\n",
        "# The objective of this dataset is to understand the significant risk factors responsible for maternal mortality by collecting\n",
        "# data from different hospitals, community clinics, maternal health cares from the rural \n",
        "# areas of Bangladesh through the IoT based risk monitoring system.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. **Attribute Analysis**: \n",
        "\n",
        "    3.1 Determine which attributes lack informativeness and should be excluded to prove the effectiveness of the machine learning analysis. If all features are emed relevant, explicitly state this conclusion.\n",
        "\n",
        "    3.2 Examine the distribution of each attribute (column) within the dataset. Utilize histograms or boxplots to visualize the distributions, identifying any underlying patterns or outliers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. **Class Distribution Analysis**: Investigate the distribution of class labels within the dataset. Employ bar plots to visualize the frequency of instances for each class, and assess whether the dataset is balanced or imbalanced."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. **Preprocessing**: \n",
        "\n",
        "    5.1 For numerical features, determine the best transformation to use. Indicate e transformation that seems appropriate and why. Include the code illustrating how  apply the transformation. For at least one attribute, show the distribution before d after the transformation. See [Preprocessing data](https://scikit-learn.org/able/modules/preprocessing.html).\n",
        "\n",
        "    5.2 For categorical features, show how to apply [one-hot encoding](https://ikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html).  your dataset does not have categorical data, show how to apply the one-hot encoder  the label (target variable)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "6. **Training and target data**: Set the Python variable `X` to designate the data and `y` to designate the target class. Make sure to select only the informative features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "7. **Training and test sets**: Split the dataset into training and testing sets. Reserve 20% of data for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "--------------------------------------------------------------------------\n",
        "\n",
        "# References\n",
        "\n",
        "Make sure you provide references to ALL sources used (articles, code, algorithms).\n",
        "\n",
        "## AI transcript\n",
        "**Hint:** To share a link to your colab notebook, click on \"share\" on the top right. Then, under *General access* , change *Restricted* to \"Anyone with the link\"."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
